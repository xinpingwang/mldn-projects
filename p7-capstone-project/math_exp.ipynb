{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习纳米学位\n",
    "\n",
    "> ## 毕业项目——算式识别（Mathematical Expression Recognition）\n",
    "<div style=\"text-align: right\">王新平 2019 年 6 月 16 日</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget \"https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd009/MLND+Capstone/Mathematical_Expression_Recognition_train.zip\"\n",
    "#!unzip -q -d data Mathematical_Expression_Recognition_train.zip\n",
    "#!rm Mathematical_Expression_Recognition_train.zip\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化部分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "def imshow(imgs, labels, cols=4):\n",
    "    # calculate row to show images\n",
    "    rows = len(imgs) // cols + 1\n",
    "    \n",
    "    # create a new figure\n",
    "    fig = plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = fig.add_subplot(rows, cols, i + 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(labels[i])\n",
    "\n",
    "examples = data_frame.iloc[0:4]\n",
    "example_imgs = list((plt.imread(os.path.join(data_dir, x)) for x in examples['filename']))\n",
    "example_labels = examples['label'].array\n",
    "\n",
    "imshow(example_imgs, example_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "label_len_count = defaultdict(int)\n",
    "\n",
    "for label in data_frame['label']:\n",
    "    label_len_count[len(label)] += 1\n",
    "\n",
    "plt.bar(label_len_count.keys(), label_len_count.values())\n",
    "plt.xlabel('label length')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_char_count = defaultdict(int)\n",
    "\n",
    "for label in data_frame['label']:\n",
    "    for c in label:\n",
    "        label_char_count[c] += 1\n",
    "\n",
    "plt.bar(label_char_count.keys(), label_char_count.values())\n",
    "plt.xlabel('label char')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集划分为训练集、验证集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class MathExpDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_frame, root_dir, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[index, 0])\n",
    "        \n",
    "        image = plt.imread(img_name)\n",
    "        label = self.data_frame.iloc[index, 1]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_exp_dataset = MathExpDataset(data_frame=data_frame, root_dir=data_dir)\n",
    "\n",
    "samples = []\n",
    "for i in range(len(math_exp_dataset)):\n",
    "    samples.append(math_exp_dataset[i])\n",
    "    \n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "imshow(list(x['image'] for x in samples), list(x['label'] for x in samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "class ToGray(object):\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([transforms.ToPILImage(), transforms.Grayscale()])\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = self.transform(image)\n",
    "        return {'image': image, 'label': label}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert PIL Image in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        # the image after ToGray is two dims\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        return {'image': torch.from_numpy(image), 'label': label}\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, mean=[127.5], std=[127.5]):\n",
    "        self.normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        return {'image': self.normalize(image.float()), 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "to_gray = ToGray()\n",
    "plt.imshow(to_gray(math_exp_dataset[0])['image'], cmap=cm.gray, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_compose = transforms.Compose([ToGray(), ToTensor(), Normalize()])\n",
    "transformed_sample = transform_compose(math_exp_dataset[0])\n",
    "\n",
    "plt.imshow(transformed_sample['image'].numpy()[0], cmap=cm.gray, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_sample['image'].shape)\n",
    "print(transformed_sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_exp_dataset = MathExpDataset(data_frame=data_frame, root_dir=data_dir,\n",
    "                                  transform=transforms.Compose([ToGray(), ToTensor(), Normalize()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset\n",
    "\n",
    "split_lens = (len(math_exp_dataset) // 10 * 8, len(math_exp_dataset) // 10, len(math_exp_dataset) // 10)\n",
    "\n",
    "splited_temp = dataset.random_split(math_exp_dataset, split_lens)\n",
    "\n",
    "math_exp_dataset_splited = {x: splited_temp[i] \n",
    "                            for i, x in enumerate(['train', 'val', 'test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data_loaders = {x: torch.utils.data.DataLoader(math_exp_dataset_splited[x], batch_size,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "                for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_layers, num_classes):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        \n",
    "        # 默认 hidden_size 和 input_size 一致\n",
    "        self.rnn = nn.LSTM(input_size, input_size, num_layers, bidirectional=True)\n",
    "        self.embedding = nn.Linear(input_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence. \n",
    "        # The input can also be a packed variable length sequence.\n",
    "        #\n",
    "        # output of shape (seq_len, batch, num_directions * hidden_size)\n",
    "        # If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "        output, _ = self.rnn(input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class TransNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(TransNet, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim = 2)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # seq_len, batch, feature_size = input.size()\n",
    "        output = self.embedding(input)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "class ConvRecNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_size):\n",
    "        super(ConvRecNet, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(OrderedDict([\n",
    "            # batch x channels x height x width: (-1 x 1 x 64 x 300) -> (-1 x 8 x 64 x 300)\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu1', nn.ReLU()),\n",
    "            # (-1 x 8 x 64 x 300) -> (-1 x 8 x 32 x 150)\n",
    "            ('pool1', nn.MaxPool2d(2)),\n",
    "            \n",
    "            # batch x channels x height x width: (-1 x 8 x 32 x 150) -> (-1 x 16 x 32 x 150)\n",
    "            ('conv2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu2', nn.ReLU()),\n",
    "            # (-1 x 16 x 32 x 150) -> (-1 x 16 x 16 x 75)\n",
    "            ('pool2', nn.MaxPool2d(2)),\n",
    "            \n",
    "            # batch x channels x height x width: (-1 x 16 x 16 x 75) -> (-1 x 32, 16, 75)\n",
    "            ('conv3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu3', nn.ReLU()),\n",
    "            # (-1 x 32 x 16 x 75) -> (-1 x 32 x 8 x 38)\n",
    "            ('pool3', nn.MaxPool2d(2, padding=(0, 1))),\n",
    "            \n",
    "            # batch x channels x height x width: (-1 x 32 x 8 x 38) -> (-1 x 64 x 8 x 38)\n",
    "            ('conv4', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu4', nn.ReLU()),\n",
    "            # (-1 x 64 x 8 x 38) -> (-1 x 64 x 4 x 19)\n",
    "            ('pool4', nn.MaxPool2d(2)),\n",
    "            \n",
    "            # batch x channels x height x width: (-1 x 64 x 4 x 19) -> (-1 x 128 x 4 x 19)\n",
    "            ('conv5', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu5', nn.ReLU()),\n",
    "            # (-1 x 128 x 4 x 19) -> (-1 x 128 x 2 x 19)\n",
    "            ('pool5', nn.MaxPool2d((2, 1))),\n",
    "            \n",
    "            # batch x channels x height x width: (-1 x 128 x 2 x 19) -> (-1 x 256 x 2 x 19)\n",
    "            ('conv6', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)),\n",
    "            # active\n",
    "            ('relu6', nn.ReLU()),\n",
    "            # (-1 x 256 x 2 x 10) -> (-1 x 256 x 1 x 19)\n",
    "            ('pool6', nn.MaxPool2d((2, 1))),\n",
    "            \n",
    "            # linear: (-1 x 256 x 1 x 19) -> (-1 x 256 x 1 x 16)\n",
    "            ('linear', nn.Linear(19, 16)),\n",
    "            # active\n",
    "            ('relu6', nn.ReLU())\n",
    "        ]))\n",
    "        \n",
    "        self.rnn = BidirectionalLSTM(256, 2, class_size)\n",
    "        \n",
    "        self.trans = TransNet(512, class_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size() # (-1 x 256 x 1 x 19)\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2) # b, c, w (-1 x 256 x 19)\n",
    "        conv = conv.permute(2, 0, 1) # w, b, c (19, -1 x 256)\n",
    "        \n",
    "        output = self.rnn(conv)\n",
    "        \n",
    "        output = self.trans(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = '1234567890+-*=()'\n",
    "\n",
    "net = ConvRecNet(len(chars))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考连接\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/transforms/transforms.html\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
